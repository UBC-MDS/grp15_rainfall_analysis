{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import glob\n",
    "import zipfile\n",
    "import requests\n",
    "from urllib.request import urlretrieve\n",
    "import json\n",
    "import pandas as pd\n",
    "from memory_profiler import memory_usage\n",
    "\n",
    "\n",
    "import dask.dataframe as dd\n",
    "\n",
    "\n",
    "import pyarrow.dataset as ds\n",
    "import rpy2_arrow.pyarrow_rarrow as pyra\n",
    "import pyarrow.feather as feather\n",
    "import pyarrow.parquet as pq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext rpy2.ipython\n",
    "%load_ext memory_profiler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Milestone 1: Tackling big data on your laptop\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. Downloading the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1). Download the data from [figshare](https://figshare.com/articles/dataset/Daily_rainfall_over_NSW_Australia/14096681) to the local computer using the [figshare API](https://docs.figshare.com) using the `requests` library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# article_id = 14096681\n",
    "# url = f\"https://api.figshare.com/v2/articles/{article_id}\"\n",
    "# headers = {\"Content-Type\": \"application/json\"}\n",
    "# output_directory = \"figshare_rainfall\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# response = requests.request(\"GET\", url, headers=headers)\n",
    "# data = json.loads(response.text)\n",
    "# files = data[\"files\"]\n",
    "# files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# files_to_dl = [\"data.zip\"]\n",
    "# for file in files:\n",
    "#     if file[\"name\"] in files_to_dl:\n",
    "#         os.makedirs(output_directory, exist_ok=True)\n",
    "#         urlretrieve(file[\"download_url\"], os.path.join(output_directory, file[\"name\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2). Extract the zip file programmatically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# with zipfile.ZipFile(os.path.join(output_directory, \"data.zip\"), 'r') as f:\n",
    "#     f.extractall(output_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Combining data CSVs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We used `pandas` to combine data CSVs into a single CSV.\n",
    "- An extra column called \"model\" is added which identifies the model eg: for file name \"SAM0-UNICON_daily_rainfall_NSW.csv\", the model name is SAM0-UNICON\n",
    "- The comparison of run times and memory usages of these options on different machines within our team is documented in the GitHub [issue](](https://github.com/UBC-MDS/grp15_rainfall_analysis/issues/5).\n",
    "- We observed that memory increment is quite low among different machines, which means combining entire dataset consumes small memory\n",
    "    - *Junghoo*\n",
    "        - peak memory: 359.83 MiB, increment: 0.09 MiB\n",
    "        - CPU times: user 4min 52s, sys: 9.55 s, total: 5min 22s\n",
    "        - Wall time: 5min 4s\n",
    "    - *Micah*\n",
    "         - peak memory: 347.55 MiB, increment: 0.18 MiB\n",
    "         - CPU times: user 7min 14s, sys: 26 s, total: 7min 40s\n",
    "         - Wall time: 7min 57s\n",
    "    - *Chuang*\n",
    "         - peak memory: 464.66 MiB, increment: 0.10 MiB\n",
    "         - CPU times: user 6min 19s, sys: 17 s, total: 6min 36s\n",
    "         - Wall time: 6min 51s \n",
    "    - *Pan*\n",
    "         - peak memory: 328.88 MiB, increment: 0.25 MiB\n",
    "         - CPU times: user 5min 31s, sys: 21.3 s, total: 5min 52s\n",
    "         - Wall time: 5min 59s  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ### just listing to get an idea how individual file looks like \n",
    "# sample_df = pd.read_csv(os.path.join(output_directory, \"ACCESS-CM2_daily_rainfall_NSW.csv\"))\n",
    "# sample_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### making sure that all files have the same colums\n",
    "# files = glob.glob(os.path.join(output_directory, \"*.csv\"))\n",
    "# use_cols = list(sample_df.columns)\n",
    "# for file in files:\n",
    "#     try:\n",
    "#         pd.read_csv(file, index_col=0, usecols=use_cols)\n",
    "#     except:\n",
    "#         df = pd.read_csv(file, index_col=0)\n",
    "#         print(f\"{os.path.basename(file)} does not have all columns. {os.path.basename(file)} only has {df.columns.to_list()} columns.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# %memit\n",
    "# # \"figshare_rainfall/observed_daily_rainfall_SYD.csv\" is missing 'lat_min', 'lat_max', 'lon_min', 'lon_max' columns\n",
    "# files = glob.glob(os.path.join(output_directory, \"*_NSW.csv\"))\n",
    "\n",
    "# # combining using pandas method\n",
    "# df = pd.concat((pd.read_csv(file, index_col=0, usecols=use_cols)\n",
    "#                 .assign(model = os.path.basename(file).split(\"_\")[0])\n",
    "#                 for file in files)\n",
    "#               )\n",
    "# df.to_csv(os.path.join(output_directory, \"combined_data.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Load the combined CSV to memory and perform a simple EDA\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1). simple pandas - loading the entire data to the memory\n",
    "\n",
    "\n",
    "#### ***Observation***\n",
    "- We can see that the CPU time and Wall time are really close to each other, which might mean that there might be only one CPU processing the work.\n",
    "- We can also observe that the memory increment 6049.38 MiB is quite high, which means loading the entire dataset consumes a lot of memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPI-ESM1-2-HR       5154240\n",
      "CMCC-CM2-HR4        3541230\n",
      "CMCC-CM2-SR5        3541230\n",
      "TaiESM1             3541230\n",
      "CMCC-ESM2           3541230\n",
      "NorESM2-MM          3541230\n",
      "SAM0-UNICON         3541153\n",
      "GFDL-ESM4           3219300\n",
      "FGOALS-f3-L         3219300\n",
      "GFDL-CM4            3219300\n",
      "EC-Earth3-Veg-LR    3037320\n",
      "MRI-ESM2-0          3037320\n",
      "BCC-CSM2-MR         3035340\n",
      "MIROC6              2070900\n",
      "ACCESS-CM2          1932840\n",
      "ACCESS-ESM1-5       1610700\n",
      "INM-CM5-0           1609650\n",
      "INM-CM4-8           1609650\n",
      "KIOST-ESM           1287720\n",
      "FGOALS-g3           1287720\n",
      "MPI-ESM-1-2-HAM      966420\n",
      "MPI-ESM1-2-LR        966420\n",
      "NESM3                966420\n",
      "AWI-ESM-1-1-LR       966420\n",
      "NorESM2-LM           919800\n",
      "CanESM5              551880\n",
      "BCC-ESM1             551880\n",
      "Name: model, dtype: int64\n",
      "peak memory: 6532.96 MiB, increment: 6295.71 MiB\n",
      "CPU times: user 1min 1s, sys: 11.3 s, total: 1min 12s\n",
      "Wall time: 1min 17s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%memit\n",
    "df = pd.read_csv(\"figshare_rainfall/combined_data.csv\")\n",
    "print(df[\"model\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62467843"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see how many rows in the dataset\n",
    "len(df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>lat_min</th>\n",
       "      <th>lat_max</th>\n",
       "      <th>lon_min</th>\n",
       "      <th>lon_max</th>\n",
       "      <th>rain (mm/day)</th>\n",
       "      <th>model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1889-01-01 12:00:00</td>\n",
       "      <td>-35.439867</td>\n",
       "      <td>-33.574619</td>\n",
       "      <td>141.5625</td>\n",
       "      <td>143.4375</td>\n",
       "      <td>4.244226e-13</td>\n",
       "      <td>MPI-ESM-1-2-HAM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1889-01-02 12:00:00</td>\n",
       "      <td>-35.439867</td>\n",
       "      <td>-33.574619</td>\n",
       "      <td>141.5625</td>\n",
       "      <td>143.4375</td>\n",
       "      <td>4.217326e-13</td>\n",
       "      <td>MPI-ESM-1-2-HAM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1889-01-03 12:00:00</td>\n",
       "      <td>-35.439867</td>\n",
       "      <td>-33.574619</td>\n",
       "      <td>141.5625</td>\n",
       "      <td>143.4375</td>\n",
       "      <td>4.498125e-13</td>\n",
       "      <td>MPI-ESM-1-2-HAM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1889-01-04 12:00:00</td>\n",
       "      <td>-35.439867</td>\n",
       "      <td>-33.574619</td>\n",
       "      <td>141.5625</td>\n",
       "      <td>143.4375</td>\n",
       "      <td>4.251282e-13</td>\n",
       "      <td>MPI-ESM-1-2-HAM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1889-01-05 12:00:00</td>\n",
       "      <td>-35.439867</td>\n",
       "      <td>-33.574619</td>\n",
       "      <td>141.5625</td>\n",
       "      <td>143.4375</td>\n",
       "      <td>4.270161e-13</td>\n",
       "      <td>MPI-ESM-1-2-HAM</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  time    lat_min    lat_max   lon_min   lon_max  \\\n",
       "0  1889-01-01 12:00:00 -35.439867 -33.574619  141.5625  143.4375   \n",
       "1  1889-01-02 12:00:00 -35.439867 -33.574619  141.5625  143.4375   \n",
       "2  1889-01-03 12:00:00 -35.439867 -33.574619  141.5625  143.4375   \n",
       "3  1889-01-04 12:00:00 -35.439867 -33.574619  141.5625  143.4375   \n",
       "4  1889-01-05 12:00:00 -35.439867 -33.574619  141.5625  143.4375   \n",
       "\n",
       "   rain (mm/day)            model  \n",
       "0   4.244226e-13  MPI-ESM-1-2-HAM  \n",
       "1   4.217326e-13  MPI-ESM-1-2-HAM  \n",
       "2   4.498125e-13  MPI-ESM-1-2-HAM  \n",
       "3   4.251282e-13  MPI-ESM-1-2-HAM  \n",
       "4   4.270161e-13  MPI-ESM-1-2-HAM  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# have a look at the first couple of rows of the data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "time              object\n",
       "lat_min          float64\n",
       "lat_max          float64\n",
       "lon_min          float64\n",
       "lon_max          float64\n",
       "rain (mm/day)    float64\n",
       "model             object\n",
       "dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2). Changing dtype of the data to reduce memory usage while performing\n",
    "\n",
    "#### ***Observation***\n",
    "- By changing the dtype of the 5 out of 7 columns from `float64` to `float32`, we saved half space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reduced_dtype = df[['lat_min', 'lat_max', 'lon_min', 'lon_max', 'rain (mm/day)']].astype('float32', errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage with float64: 2498.71 MB\n",
      "Memory usage with float32: 1249.36 MB\n"
     ]
    }
   ],
   "source": [
    "print(f\"Memory usage with float64: {df[['lat_min', 'lat_max', 'lon_min', 'lon_max', 'rain (mm/day)']].memory_usage().sum() / 1e6:.2f} MB\")\n",
    "print(f\"Memory usage with float32: {df_reduced_dtype.memory_usage().sum() / 1e6:.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3). Loading in chunks\n",
    "#### ***Observation***\n",
    "- memory increment: 1116.05 MiB is dramatically decreased (it was 6049.38 MiB using pandas) when we load data in small chunks.\n",
    "- But the CPU time and Wall time are still close to each other, which means the work is still ***not*** executed parallely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCESS-CM2          1932840\n",
      "ACCESS-ESM1-5       1610700\n",
      "AWI-ESM-1-1-LR       966420\n",
      "BCC-CSM2-MR         3035340\n",
      "BCC-ESM1             551880\n",
      "CMCC-CM2-HR4        3541230\n",
      "CMCC-CM2-SR5        3541230\n",
      "CMCC-ESM2           3541230\n",
      "CanESM5              551880\n",
      "EC-Earth3-Veg-LR    3037320\n",
      "FGOALS-f3-L         3219300\n",
      "FGOALS-g3           1287720\n",
      "GFDL-CM4            3219300\n",
      "GFDL-ESM4           3219300\n",
      "INM-CM4-8           1609650\n",
      "INM-CM5-0           1609650\n",
      "KIOST-ESM           1287720\n",
      "MIROC6              2070900\n",
      "MPI-ESM-1-2-HAM      966420\n",
      "MPI-ESM1-2-HR       5154240\n",
      "MPI-ESM1-2-LR        966420\n",
      "MRI-ESM2-0          3037320\n",
      "NESM3                966420\n",
      "NorESM2-LM           919800\n",
      "NorESM2-MM          3541230\n",
      "SAM0-UNICON         3541153\n",
      "TaiESM1             3541230\n",
      "dtype: int64\n",
      "peak memory: 7696.09 MiB, increment: 1344.12 MiB\n",
      "CPU times: user 1min 1s, sys: 7.4 s, total: 1min 8s\n",
      "Wall time: 1min 10s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%memit\n",
    "counts = pd.Series(dtype=int)\n",
    "for chunk in pd.read_csv(\"figshare_rainfall/combined_data.csv\", chunksize=10_000_000):\n",
    "    counts = counts.add(chunk[\"model\"].value_counts(), fill_value=0)\n",
    "print(counts.astype(int))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4). Dask Way\n",
    "\n",
    "> using `dask` to read that csv file. Internally its loading chunks and doing it parallely.\n",
    "\n",
    "#### ***Observation***\n",
    "- memory increment: 1291.08 MiB is dramatically decreased (it was 1116.05 MiB using pandas) when we load data in small chunks.\n",
    "- However, the CPU time is much greater than the Wall time now, which means the work was done by several processors concurrently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPI-ESM1-2-HR       5154240\n",
      "TaiESM1             3541230\n",
      "NorESM2-MM          3541230\n",
      "CMCC-CM2-HR4        3541230\n",
      "CMCC-CM2-SR5        3541230\n",
      "CMCC-ESM2           3541230\n",
      "SAM0-UNICON         3541153\n",
      "FGOALS-f3-L         3219300\n",
      "GFDL-CM4            3219300\n",
      "GFDL-ESM4           3219300\n",
      "EC-Earth3-Veg-LR    3037320\n",
      "MRI-ESM2-0          3037320\n",
      "BCC-CSM2-MR         3035340\n",
      "MIROC6              2070900\n",
      "ACCESS-CM2          1932840\n",
      "ACCESS-ESM1-5       1610700\n",
      "INM-CM5-0           1609650\n",
      "INM-CM4-8           1609650\n",
      "KIOST-ESM           1287720\n",
      "FGOALS-g3           1287720\n",
      "MPI-ESM1-2-LR        966420\n",
      "NESM3                966420\n",
      "AWI-ESM-1-1-LR       966420\n",
      "MPI-ESM-1-2-HAM      966420\n",
      "NorESM2-LM           919800\n",
      "BCC-ESM1             551880\n",
      "CanESM5              551880\n",
      "Name: model, dtype: int64\n",
      "peak memory: 5125.86 MiB, increment: 1338.71 MiB\n",
      "CPU times: user 1min 27s, sys: 17.8 s, total: 1min 45s\n",
      "Wall time: 41.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%memit\n",
    "ddf = dd.read_csv('figshare_rainfall/combined_data.csv')\n",
    "print(ddf[\"model\"].value_counts().compute())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Perform a simple EDA in R"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1). Loading Datasets into Different Formats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a). pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 3702.75 MiB, increment: 16.93 MiB\n",
      "CPU times: user 1.02 s, sys: 127 ms, total: 1.15 s\n",
      "Wall time: 2.11 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%memit\n",
    "df = pd.read_csv(\"figshare_rainfall/combined_data.csv\", nrows=1_000_000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b). arrow table format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 4854.95 MiB, increment: 1236.44 MiB\n",
      "CPU times: user 20.3 s, sys: 10.8 s, total: 31.1 s\n",
      "Wall time: 27.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%memit\n",
    "\n",
    "#loading datasets\n",
    "\n",
    "dataset = ds.dataset(\"figshare_rainfall/combined_data.csv\", format=\"csv\")\n",
    "table = dataset.to_table()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c). feather format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 5319.28 MiB, increment: 1758.34 MiB\n",
      "CPU times: user 4.92 s, sys: 12.3 s, total: 17.2 s\n",
      "Wall time: 9.47 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%memit\n",
    "# writing to feather format\n",
    "feather.write_feather(table, 'figshare_rainfall/combined.feather')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### d). parquet format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 5459.55 MiB, increment: 138.73 MiB\n",
      "CPU times: user 9.63 s, sys: 1.77 s, total: 11.4 s\n",
      "Wall time: 13.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%memit\n",
    "## writing as a single parquet \n",
    "pq.write_table(table, 'figshare_rainfall/combined.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compare the size of the data in 3 different format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.6G\tfigshare_rainfall/combined_data.csv\n",
      "1.0G\tfigshare_rainfall/combined.feather\n",
      "544M\tfigshare_rainfall/combined.parquet\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "# I am just seeing the size of the csv data\n",
    "du -sh figshare_rainfall/combined_data.csv\n",
    "# I am just seeing the size of the feather data\n",
    "du -sh figshare_rainfall/combined.feather\n",
    "# I am just seeing the size of the parquet data\n",
    "du -sh figshare_rainfall/combined.parquet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2). Transfering to R and trying to do simple EDA - `count(model)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a). pandas\n",
    "\n",
    "> Note: we tried to load the entire dataset into R from python pandas object, but it takes ages :| Therefore, we decided to load just 1 million rows of the data, which is just 1.6% of the whole dataset. However, loading the 1.6% of the whole dataset and performing `count(model)` took same amount of time as it does for the whole dataset in arrow table format. This indicates that the exchange of data between python pandas object and R is a really expensive operation because of the serialization and deserialization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: \n",
      "Attaching package: ‘dplyr’\n",
      "\n",
      "\n",
      "R[write to console]: The following objects are masked from ‘package:stats’:\n",
      "\n",
      "    filter, lag\n",
      "\n",
      "\n",
      "R[write to console]: The following objects are masked from ‘package:base’:\n",
      "\n",
      "    intersect, setdiff, setequal, union\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"data.frame\"\n",
      "            model      n\n",
      "1  AWI-ESM-1-1-LR  33580\n",
      "2 MPI-ESM-1-2-HAM 966420\n",
      "Time difference of 0.7901061 secs\n",
      "CPU times: user 27.6 s, sys: 1.13 s, total: 28.7 s\n",
      "Wall time: 29.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%R -i df\n",
    "## transferring the python dataframe to R\n",
    "start_time <- Sys.time()\n",
    "library(dplyr)\n",
    "print(class(df))\n",
    "result <- df %>% count(model)\n",
    "print(result)\n",
    "end_time <- Sys.time()\n",
    "print(end_time - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b). in arrow table format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5695\n",
      "rarrow.ChunkedArray: 0.024595975875854492\n",
      "5695\n",
      "rarrow.ChunkedArray: 0.02149200439453125\n",
      "5695\n",
      "rarrow.ChunkedArray: 0.022471189498901367\n",
      "5695\n",
      "rarrow.ChunkedArray: 0.027393579483032227\n",
      "5695\n",
      "rarrow.ChunkedArray: 0.029187679290771484\n",
      "5695\n",
      "rarrow.ChunkedArray: 0.027768850326538086\n",
      "5695\n",
      "rarrow.ChunkedArray: 0.023662090301513672\n",
      "peak memory: 6099.84 MiB, increment: 61.80 MiB\n",
      "CPU times: user 24.8 s, sys: 639 ms, total: 25.4 s\n",
      "Wall time: 26.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%memit\n",
    "## Here we are loading the arrow dataframe that we have loaded previously\n",
    "\n",
    "r_table = pyra.converter.py2rpy(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Table\"       \"ArrowObject\" \"R6\"         \n",
      "[1] \"tbl_df\"     \"tbl\"        \"data.frame\"\n",
      "\u001b[90m# A tibble: 27 x 2\u001b[39m\n",
      "   model                  n\n",
      "   \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m              \u001b[3m\u001b[90m<int>\u001b[39m\u001b[23m\n",
      "\u001b[90m 1\u001b[39m ACCESS-CM2       1\u001b[4m9\u001b[24m\u001b[4m3\u001b[24m\u001b[4m2\u001b[24m840\n",
      "\u001b[90m 2\u001b[39m ACCESS-ESM1-5    1\u001b[4m6\u001b[24m\u001b[4m1\u001b[24m\u001b[4m0\u001b[24m700\n",
      "\u001b[90m 3\u001b[39m AWI-ESM-1-1-LR    \u001b[4m9\u001b[24m\u001b[4m6\u001b[24m\u001b[4m6\u001b[24m420\n",
      "\u001b[90m 4\u001b[39m BCC-CSM2-MR      3\u001b[4m0\u001b[24m\u001b[4m3\u001b[24m\u001b[4m5\u001b[24m340\n",
      "\u001b[90m 5\u001b[39m BCC-ESM1          \u001b[4m5\u001b[24m\u001b[4m5\u001b[24m\u001b[4m1\u001b[24m880\n",
      "\u001b[90m 6\u001b[39m CanESM5           \u001b[4m5\u001b[24m\u001b[4m5\u001b[24m\u001b[4m1\u001b[24m880\n",
      "\u001b[90m 7\u001b[39m CMCC-CM2-HR4     3\u001b[4m5\u001b[24m\u001b[4m4\u001b[24m\u001b[4m1\u001b[24m230\n",
      "\u001b[90m 8\u001b[39m CMCC-CM2-SR5     3\u001b[4m5\u001b[24m\u001b[4m4\u001b[24m\u001b[4m1\u001b[24m230\n",
      "\u001b[90m 9\u001b[39m CMCC-ESM2        3\u001b[4m5\u001b[24m\u001b[4m4\u001b[24m\u001b[4m1\u001b[24m230\n",
      "\u001b[90m10\u001b[39m EC-Earth3-Veg-LR 3\u001b[4m0\u001b[24m\u001b[4m3\u001b[24m\u001b[4m7\u001b[24m320\n",
      "\u001b[90m# … with 17 more rows\u001b[39m\n",
      "Time difference of 10.11736 secs\n",
      "CPU times: user 10.3 s, sys: 12.4 s, total: 22.8 s\n",
      "Wall time: 10.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%R -i r_table\n",
    "\n",
    "## arrow Speed\n",
    "start_time <- Sys.time()\n",
    "print(class(r_table))\n",
    "##add details on collect here\n",
    "library(dplyr)\n",
    "# Arrow speed\n",
    "result <- r_table %>% collect() %>% count(model)\n",
    "print(class(r_table %>% collect()))\n",
    "end_time <- Sys.time()\n",
    "print(result)\n",
    "print(end_time - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c). in Feather format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"tbl_df\"     \"tbl\"        \"data.frame\"\n",
      "\u001b[90m# A tibble: 27 x 2\u001b[39m\n",
      "   model                  n\n",
      "   \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m              \u001b[3m\u001b[90m<int>\u001b[39m\u001b[23m\n",
      "\u001b[90m 1\u001b[39m ACCESS-CM2       1\u001b[4m9\u001b[24m\u001b[4m3\u001b[24m\u001b[4m2\u001b[24m840\n",
      "\u001b[90m 2\u001b[39m ACCESS-ESM1-5    1\u001b[4m6\u001b[24m\u001b[4m1\u001b[24m\u001b[4m0\u001b[24m700\n",
      "\u001b[90m 3\u001b[39m AWI-ESM-1-1-LR    \u001b[4m9\u001b[24m\u001b[4m6\u001b[24m\u001b[4m6\u001b[24m420\n",
      "\u001b[90m 4\u001b[39m BCC-CSM2-MR      3\u001b[4m0\u001b[24m\u001b[4m3\u001b[24m\u001b[4m5\u001b[24m340\n",
      "\u001b[90m 5\u001b[39m BCC-ESM1          \u001b[4m5\u001b[24m\u001b[4m5\u001b[24m\u001b[4m1\u001b[24m880\n",
      "\u001b[90m 6\u001b[39m CanESM5           \u001b[4m5\u001b[24m\u001b[4m5\u001b[24m\u001b[4m1\u001b[24m880\n",
      "\u001b[90m 7\u001b[39m CMCC-CM2-HR4     3\u001b[4m5\u001b[24m\u001b[4m4\u001b[24m\u001b[4m1\u001b[24m230\n",
      "\u001b[90m 8\u001b[39m CMCC-CM2-SR5     3\u001b[4m5\u001b[24m\u001b[4m4\u001b[24m\u001b[4m1\u001b[24m230\n",
      "\u001b[90m 9\u001b[39m CMCC-ESM2        3\u001b[4m5\u001b[24m\u001b[4m4\u001b[24m\u001b[4m1\u001b[24m230\n",
      "\u001b[90m10\u001b[39m EC-Earth3-Veg-LR 3\u001b[4m0\u001b[24m\u001b[4m3\u001b[24m\u001b[4m7\u001b[24m320\n",
      "\u001b[90m# … with 17 more rows\u001b[39m\n",
      "Time difference of 19.67986 secs\n",
      "CPU times: user 11 s, sys: 20.7 s, total: 31.8 s\n",
      "Wall time: 19.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%R\n",
    "\n",
    "### Feather speed\n",
    "\n",
    "library(arrow)\n",
    "start_time <- Sys.time()\n",
    "r_table <- arrow::read_feather(\"figshare_rainfall/combined.feather\")\n",
    "print(class(r_table))\n",
    "library(dplyr)\n",
    "result <- r_table %>% count(model)\n",
    "end_time <- Sys.time()\n",
    "print(result)\n",
    "print(end_time - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### d). in Parquet format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"tbl_df\"     \"tbl\"        \"data.frame\"\n",
      "\u001b[90m# A tibble: 27 x 2\u001b[39m\n",
      "   model                  n\n",
      "   \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m              \u001b[3m\u001b[90m<int>\u001b[39m\u001b[23m\n",
      "\u001b[90m 1\u001b[39m ACCESS-CM2       1\u001b[4m9\u001b[24m\u001b[4m3\u001b[24m\u001b[4m2\u001b[24m840\n",
      "\u001b[90m 2\u001b[39m ACCESS-ESM1-5    1\u001b[4m6\u001b[24m\u001b[4m1\u001b[24m\u001b[4m0\u001b[24m700\n",
      "\u001b[90m 3\u001b[39m AWI-ESM-1-1-LR    \u001b[4m9\u001b[24m\u001b[4m6\u001b[24m\u001b[4m6\u001b[24m420\n",
      "\u001b[90m 4\u001b[39m BCC-CSM2-MR      3\u001b[4m0\u001b[24m\u001b[4m3\u001b[24m\u001b[4m5\u001b[24m340\n",
      "\u001b[90m 5\u001b[39m BCC-ESM1          \u001b[4m5\u001b[24m\u001b[4m5\u001b[24m\u001b[4m1\u001b[24m880\n",
      "\u001b[90m 6\u001b[39m CanESM5           \u001b[4m5\u001b[24m\u001b[4m5\u001b[24m\u001b[4m1\u001b[24m880\n",
      "\u001b[90m 7\u001b[39m CMCC-CM2-HR4     3\u001b[4m5\u001b[24m\u001b[4m4\u001b[24m\u001b[4m1\u001b[24m230\n",
      "\u001b[90m 8\u001b[39m CMCC-CM2-SR5     3\u001b[4m5\u001b[24m\u001b[4m4\u001b[24m\u001b[4m1\u001b[24m230\n",
      "\u001b[90m 9\u001b[39m CMCC-ESM2        3\u001b[4m5\u001b[24m\u001b[4m4\u001b[24m\u001b[4m1\u001b[24m230\n",
      "\u001b[90m10\u001b[39m EC-Earth3-Veg-LR 3\u001b[4m0\u001b[24m\u001b[4m3\u001b[24m\u001b[4m7\u001b[24m320\n",
      "\u001b[90m# … with 17 more rows\u001b[39m\n",
      "Time difference of 10.07803 secs\n",
      "CPU times: user 10.1 s, sys: 5.41 s, total: 15.5 s\n",
      "Wall time: 10.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%R\n",
    "\n",
    "### Parquet speed\n",
    "\n",
    "library(arrow)\n",
    "start_time <- Sys.time()\n",
    "r_table <- arrow::read_parquet(\"figshare_rainfall/combined.parquet\")\n",
    "print(class(r_table))\n",
    "library(dplyr)\n",
    "result <- r_table %>% count(model)\n",
    "end_time <- Sys.time()\n",
    "print(result)\n",
    "print(end_time - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3). Transfering to R and trying to do simple EDA - `summary()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a). pandas\n",
    "\n",
    "> Note: Again, we tried to load the entire dataset into R from python pandas object, but it takes ages :| Therefore, we decided to load just 1 million rows of the data, which is just 1.6% of the whole dataset. However, loading the 1.6% of the whole dataset and performing `summary()` took same amount of time as it does for the whole dataset in arrow table format. This indicates that the exchange of data between python pandas object and R is a really expensive operation because of the serialization and deserialization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"data.frame\"\n",
      "     time              lat_min          lat_max          lon_min     \n",
      " Length:1000000     Min.   :-35.44   Min.   :-33.57   Min.   :141.6  \n",
      " Class :character   1st Qu.:-35.44   1st Qu.:-33.57   1st Qu.:143.4  \n",
      " Mode  :character   Median :-33.57   Median :-31.71   Median :147.2  \n",
      "                    Mean   :-33.64   Mean   :-31.77   Mean   :147.0  \n",
      "                    3rd Qu.:-31.71   3rd Qu.:-29.84   3rd Qu.:150.9  \n",
      "                    Max.   :-31.71   Max.   :-29.84   Max.   :152.8  \n",
      "    lon_max      rain (mm/day)        model          \n",
      " Min.   :143.4   Min.   : 0.0000   Length:1000000    \n",
      " 1st Qu.:145.3   1st Qu.: 0.0000   Class :character  \n",
      " Median :149.1   Median : 0.0000   Mode  :character  \n",
      " Mean   :148.9   Mean   : 1.5912                     \n",
      " 3rd Qu.:152.8   3rd Qu.: 0.3206                     \n",
      " Max.   :154.7   Max.   :94.2708                     \n",
      "Time difference of 0.1981711 secs\n",
      "CPU times: user 26.7 s, sys: 841 ms, total: 27.6 s\n",
      "Wall time: 27.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%R -i df\n",
    "\n",
    "start_time <- Sys.time()\n",
    "library(dplyr)\n",
    "print(class(df))\n",
    "result <- df %>% collect() %>% summary()\n",
    "end_time <- Sys.time()\n",
    "print(result)\n",
    "print(end_time - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b). in arrow table format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Table\"       \"ArrowObject\" \"R6\"         \n",
      "[1] \"tbl_df\"     \"tbl\"        \"data.frame\"\n",
      "      time                        lat_min           lat_max      \n",
      " Min.   :1888-12-31 16:00:00   Min.   :-36       Min.   :-36.00  \n",
      " 1st Qu.:1920-07-02 04:00:00   1st Qu.:-35       1st Qu.:-33.66  \n",
      " Median :1952-01-01 04:00:00   Median :-33       Median :-32.04  \n",
      " Mean   :1952-01-01 08:32:08   Mean   :-33       Mean   :-31.98  \n",
      " 3rd Qu.:1983-07-02 05:00:00   3rd Qu.:-31       3rd Qu.:-30.16  \n",
      " Max.   :2014-12-31 04:00:00   Max.   :-30       Max.   :-27.91  \n",
      "                               NA's   :3219300                   \n",
      "    lon_min           lon_max      rain (mm/day)        model          \n",
      " Min.   :141       Min.   :141.2   Min.   :  0       Length:62467843   \n",
      " 1st Qu.:143       1st Qu.:145.0   1st Qu.:  0       Class :character  \n",
      " Median :147       Median :148.1   Median :  0       Mode  :character  \n",
      " Mean   :147       Mean   :148.2   Mean   :  2                         \n",
      " 3rd Qu.:150       3rd Qu.:151.3   3rd Qu.:  1                         \n",
      " Max.   :154       Max.   :155.6   Max.   :433                         \n",
      " NA's   :3219300                   NA's   :3219300                     \n",
      "Time difference of 28.32654 secs\n",
      "CPU times: user 21.7 s, sys: 19.7 s, total: 41.4 s\n",
      "Wall time: 28.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%R -i r_table\n",
    "\n",
    "## arrow Speed - running summary()\n",
    "start_time <- Sys.time()\n",
    "print(class(r_table))\n",
    "##add details on collect here\n",
    "library(dplyr)\n",
    "# Arrow speed\n",
    "result <- r_table %>% collect() %>% summary()\n",
    "print(class(r_table %>% collect()))\n",
    "end_time <- Sys.time()\n",
    "print(result)\n",
    "print(end_time - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c). in Feather format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"tbl_df\"     \"tbl\"        \"data.frame\"\n",
      "      time                        lat_min           lat_max      \n",
      " Min.   :1888-12-31 16:00:00   Min.   :-36       Min.   :-36.00  \n",
      " 1st Qu.:1920-07-02 04:00:00   1st Qu.:-35       1st Qu.:-33.66  \n",
      " Median :1952-01-01 04:00:00   Median :-33       Median :-32.04  \n",
      " Mean   :1952-01-01 08:32:08   Mean   :-33       Mean   :-31.98  \n",
      " 3rd Qu.:1983-07-02 05:00:00   3rd Qu.:-31       3rd Qu.:-30.16  \n",
      " Max.   :2014-12-31 04:00:00   Max.   :-30       Max.   :-27.91  \n",
      "                               NA's   :3219300                   \n",
      "    lon_min           lon_max      rain (mm/day)        model          \n",
      " Min.   :141       Min.   :141.2   Min.   :  0       Length:62467843   \n",
      " 1st Qu.:143       1st Qu.:145.0   1st Qu.:  0       Class :character  \n",
      " Median :147       Median :148.1   Median :  0       Mode  :character  \n",
      " Mean   :147       Mean   :148.2   Mean   :  2                         \n",
      " 3rd Qu.:150       3rd Qu.:151.3   3rd Qu.:  1                         \n",
      " Max.   :154       Max.   :155.6   Max.   :433                         \n",
      " NA's   :3219300                   NA's   :3219300                     \n",
      "Time difference of 44.45746 secs\n",
      "CPU times: user 23.5 s, sys: 29.8 s, total: 53.3 s\n",
      "Wall time: 44.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%R\n",
    "\n",
    "### Feather speed - running summary()\n",
    "\n",
    "library(arrow)\n",
    "start_time <- Sys.time()\n",
    "r_table <- arrow::read_feather(\"figshare_rainfall/combined.feather\")\n",
    "print(class(r_table))\n",
    "library(dplyr)\n",
    "result <- r_table %>% summary()\n",
    "end_time <- Sys.time()\n",
    "print(result)\n",
    "print(end_time - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### d). in Parquet format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"tbl_df\"     \"tbl\"        \"data.frame\"\n",
      "      time                        lat_min           lat_max      \n",
      " Min.   :1888-12-31 16:00:00   Min.   :-36       Min.   :-36.00  \n",
      " 1st Qu.:1920-07-02 04:00:00   1st Qu.:-35       1st Qu.:-33.66  \n",
      " Median :1952-01-01 04:00:00   Median :-33       Median :-32.04  \n",
      " Mean   :1952-01-01 08:32:08   Mean   :-33       Mean   :-31.98  \n",
      " 3rd Qu.:1983-07-02 05:00:00   3rd Qu.:-31       3rd Qu.:-30.16  \n",
      " Max.   :2014-12-31 04:00:00   Max.   :-30       Max.   :-27.91  \n",
      "                               NA's   :3219300                   \n",
      "    lon_min           lon_max      rain (mm/day)        model          \n",
      " Min.   :141       Min.   :141.2   Min.   :  0       Length:62467843   \n",
      " 1st Qu.:143       1st Qu.:145.0   1st Qu.:  0       Class :character  \n",
      " Median :147       Median :148.1   Median :  0       Mode  :character  \n",
      " Mean   :147       Mean   :148.2   Mean   :  2                         \n",
      " 3rd Qu.:150       3rd Qu.:151.3   3rd Qu.:  1                         \n",
      " Max.   :154       Max.   :155.6   Max.   :433                         \n",
      " NA's   :3219300                   NA's   :3219300                     \n",
      "Time difference of 27.12782 secs\n",
      "CPU times: user 22.9 s, sys: 14.2 s, total: 37.1 s\n",
      "Wall time: 27.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%R\n",
    "\n",
    "### Parquet speed - running summary()\n",
    "\n",
    "library(arrow)\n",
    "start_time <- Sys.time()\n",
    "r_table <- arrow::read_parquet(\"figshare_rainfall/combined.parquet\")\n",
    "print(class(r_table))\n",
    "library(dplyr)\n",
    "result <- r_table %>% summary()\n",
    "end_time <- Sys.time()\n",
    "print(result)\n",
    "print(end_time - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4). Decision**\n",
    "\n",
    "Our group chose to go with parquet to transfer the dataframe from Python to R. The file size for our combined data in parquet format was 544mb compared to 5.6GB and 1.0GB for csv and feather formats respectively. Meanwhile in the task of reading the file in R and running a simple `count(model)`, in parquet it had a wall time of 39 seconds which was compared to 40.6 seconds for arrow format and 1 minute and 23 seconds with feather format. \n",
    "\n",
    "While speed wise it seems that parquet and arrow do not differ too much, when we consider the file size of a parquet file compared to a csv it becomes the parquet format seems to be the better option.  Thus we decided to go with the parquet format to transfer the dataframe in R. \n",
    "\n",
    "We did not consider simply importing the pandas dataframe through `%%R -i` because of the amount of serialization and deserialization that would have to be done when transferring it from Python to R."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:525]",
   "language": "python",
   "name": "conda-env-525-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
